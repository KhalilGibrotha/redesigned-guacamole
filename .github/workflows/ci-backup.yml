---
name: ğŸš€ CI/CD Pipeline

on:
  workflow_call:
    inputs:
      full_scan:
        description: 'Run full codebase scan (not just changed files)'
        required: false
        type: boolean
        default: true
      branch_name:
        description: 'Branch name to checkout'
        required: false
        type: string
        default: ''
    secrets:
      CONFLUENCE_URL:
        required: false
      CONFLUENCE_USER:
        required: false
      CONFLUENCE_API_TOKEN:
        required: false

jobs:
  # Job to detect what types of files have changed
  detect-changes:
    name: ğŸ” Detect File Changes
    runs-on: ubuntu-latest
    outputs:
      docs-changed: ${{ steps.changes.outputs.docs }}
      ansible-changed: ${{ steps.changes.outputs.ansible }}
      python-changed: ${{ steps.changes.outputs.python }}
      workflows-changed: ${{ steps.changes.outputs.workflows }}
      any-code-changed: ${{ steps.changes.outputs.code }}
    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: ğŸ” Detect Changed Files
        uses: dorny/paths-filter@v3
        id: changes
        with:
          filters: |
            docs:
              - 'docs/**'
              - '*.md'
              - 'README*'
            ansible:
              - 'playbooks/**'
              - 'roles/**'
              - 'inventory/**'
              - 'vars/**'
              - '*.yml'
              - '*.yaml'
              - '.ansible-lint'
              - 'ansible.cfg'
            python:
              - '**/*.py'
              - 'requirements*.txt'
              - 'pyproject.toml'
              - '.flake8'
              - '.pylintrc'
            workflows:
              - '.github/workflows/**'
              - '.github/super-linter*'
            code:
              - '**/*.py'
              - '**/*.yml'
              - '**/*.yaml'
              - '**/*.sh'
              - '**/*.json'
              - '.github/workflows/**'

  ansible-syntax-check:
    name: ğŸ­ Ansible Syntax Check
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.ansible-changed == 'true' || inputs.full_scan == true
            docs:
              - 'docs/**'
              - '*.md'
              - 'README*'
            ansible:
              - 'playbooks/**'
              - 'roles/**'
              - 'inventory/**'
              - 'vars/**'
              - '*.yml'
              - '*.yaml'
              - '.ansible-lint'
              - 'ansible.cfg'
            python:
              - '**/*.py'
              - 'requirements*.txt'
              - 'pyproject.toml'
              - '.flake8'
              - '.pylintrc'
            workflows:
              - '.github/workflows/**'
              - '.github/super-linter*'
            code:
              - '**/*.py'
              - '**/*.yml'
              - '**/*.yaml'
              - '**/*.sh'
              - '**/*.json'
              - '.github/workflows/**'

  super-linter:
    name: ğŸ” Super Linter
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.any-code-changed == 'true' || inputs.full_scan == true

    permissions:
      contents: read
      packages: read
      statuses: write
      security-events: write

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: ğŸ”§ Configure Environment
        id: config
        run: |
          # Dynamic branch detection
          if [ "${{ github.event.repository.default_branch }}" != "" ]; then
            echo "default_branch=${{ github.event.repository.default_branch }}" >> $GITHUB_OUTPUT
          else
            echo "default_branch=main" >> $GITHUB_OUTPUT
          fi

      - name: ğŸ” Verify Linter Configuration Files
        run: |
          echo "ğŸ” Checking for linter configuration files..."

          # Check for .ansible-lint
          if [ -f ".ansible-lint" ]; then
            echo "âœ… .ansible-lint found ($(wc -l < .ansible-lint) lines)"
            echo "ğŸ“„ .ansible-lint preview:"
            head -5 .ansible-lint
          else
            echo "âŒ .ansible-lint not found"
          fi

          # Check for .yamllint
          if [ -f ".yamllint" ]; then
            echo "âœ… .yamllint found ($(wc -l < .yamllint) lines)"
          else
            echo "âŒ .yamllint not found"
          fi

          # Check for markdownlint config (prefer .json)
          if [ -f ".markdownlint.json" ]; then
            echo "âœ… .markdownlint.json found ($(wc -l < .markdownlint.json) lines)"
          elif [ -f ".markdownlint.yml" ]; then
            echo "âœ… .markdownlint.yml found ($(wc -l < .markdownlint.yml) lines)"
          else
            echo "âŒ No markdownlint config found"
          fi

          # Check for any conflicting config files
          if [ -f ".markdownlint.json" ] && [ -f ".markdownlint.yml" ]; then
            echo "âš ï¸  Both .markdownlint.json and .markdownlint.yml found - Super Linter will prefer .json"
          fi

          echo "ğŸ¯ Super Linter will auto-detect all configuration files at repo root"

      - name: ğŸ” Detect Files for Validation
        id: detect-files
        run: |
          echo "ğŸ” Detecting file types for intelligent validation..."
          
          # Check for different file types and set outputs (with proper quoting)
          yaml_files=$(find . -type f \( -name "*.yml" -o -name "*.yaml" \) ! -path "./.git/*" | wc -l)
          ansible_files=$(find . -type f -name "*.yml" \( -path "./playbooks/*" -o -path "./roles/*" \) -o -name "site.yml" -o -name "playbook*.yml" | wc -l)
          python_files=$(find . -type f -name "*.py" ! -path "./.git/*" ! -path "./.venv/*" ! -path "./venv/*" | wc -l)
          markdown_files=$(find . -type f -name "*.md" ! -path "./.git/*" | wc -l)
          shell_files=$(find . -type f -name "*.sh" ! -path "./.git/*" | wc -l)
          json_files=$(find . -type f -name "*.json" ! -path "./.git/*" ! -path "./node_modules/*" | wc -l)
          github_actions_files=$(find .github/workflows -type f \( -name "*.yml" -o -name "*.yaml" \) 2>/dev/null | wc -l)
          
          # Set outputs
          echo "yaml_files=$yaml_files" >> $GITHUB_OUTPUT
          echo "ansible_files=$ansible_files" >> $GITHUB_OUTPUT
          echo "python_files=$python_files" >> $GITHUB_OUTPUT
          echo "markdown_files=$markdown_files" >> $GITHUB_OUTPUT
          echo "shell_files=$shell_files" >> $GITHUB_OUTPUT
          echo "json_files=$json_files" >> $GITHUB_OUTPUT
          echo "github_actions_files=$github_actions_files" >> $GITHUB_OUTPUT
          
          # Output summary
          echo "ğŸ“Š File detection summary:"
          echo "  - YAML files: $yaml_files"
          echo "  - Ansible files: $ansible_files"
          echo "  - Python files: $python_files"
          echo "  - Markdown files: $markdown_files"
          echo "  - Shell files: $shell_files"
          echo "  - JSON files: $json_files"
          echo "  - GitHub Actions files: $github_actions_files"

      - name: âš™ï¸ Generate Dynamic Super Linter Configuration
        id: generate-config
        run: |
          echo "âš™ï¸ Generating dynamic Super Linter configuration..."
          
          # Set boolean values based on file detection
          yaml_validation=$([ "${{ steps.detect-files.outputs.yaml_files }}" -gt 0 ] && echo "true" || echo "false")
          ansible_validation=$([ "${{ steps.detect-files.outputs.ansible_files }}" -gt 0 ] && echo "true" || echo "false")
          markdown_validation=$([ "${{ steps.detect-files.outputs.markdown_files }}" -gt 0 ] && echo "true" || echo "false")
          python_validation=$([ "${{ steps.detect-files.outputs.python_files }}" -gt 0 ] && echo "true" || echo "false")
          shell_validation=$([ "${{ steps.detect-files.outputs.shell_files }}" -gt 0 ] && echo "true" || echo "false")
          json_validation=$([ "${{ steps.detect-files.outputs.json_files }}" -gt 0 ] && echo "true" || echo "false")
          github_actions_validation=$([ "${{ steps.detect-files.outputs.github_actions_files }}" -gt 0 ] && echo "true" || echo "false")
          
          # Set validate all codebase based on input or event type
          if [[ "${{ inputs.full_scan }}" == "true" ]] || [[ "${{ github.event_name }}" == "schedule" ]] || [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            validate_all_codebase="true"
          else
            validate_all_codebase="false"
          fi
          
          # Create the dynamic configuration file
          cat > .github/super-linter-dynamic.env << 'ENVEOF'
          # Super Linter Dynamic Configuration
          # Generated by CI workflow based on runtime conditions
          
          ##########################
          # Branch and Git Settings
          ##########################
          
          # Default branch for comparison (dynamically set)
          DEFAULT_BRANCH=BRANCH_PLACEHOLDER
          
          # Validate all files vs changed files only
          VALIDATE_ALL_CODEBASE=VALIDATE_ALL_PLACEHOLDER
          
          ##########################
          # Intelligent Validation Toggles
          # (Based on file presence detection)
          ##########################
          
          # Enable validation only if files of that type exist
          VALIDATE_YAML=YAML_PLACEHOLDER
          VALIDATE_ANSIBLE=ANSIBLE_PLACEHOLDER
          VALIDATE_MARKDOWN=MARKDOWN_PLACEHOLDER
          VALIDATE_PYTHON=PYTHON_PLACEHOLDER
          VALIDATE_BASH=BASH_PLACEHOLDER
          VALIDATE_JSON=JSON_PLACEHOLDER
          VALIDATE_SHELL_SHFMT=SHELL_PLACEHOLDER
          VALIDATE_GITHUB_ACTIONS=GITHUB_ACTIONS_PLACEHOLDER
          
          ##########################
          # Auto-fix Configuration
          ##########################
          
          # Enable auto-fixing for supported linters (only if files exist)
          FIX_YAML=FIX_YAML_PLACEHOLDER
          FIX_MARKDOWN=FIX_MARKDOWN_PLACEHOLDER
          FIX_JSON=FIX_JSON_PLACEHOLDER
          FIX_SHELL_SHFMT=FIX_SHELL_PLACEHOLDER
          
          ##########################
          # Performance Settings
          ##########################
          
          # Multi-threading for faster execution
          PARALLEL=true
          SLIM_IMAGE=true
          FAIL_FAST=false
          
          ##########################
          # Output Configuration
          ##########################
          
          # Detailed output for CI analysis
          OUTPUT_FORMAT=tap
          OUTPUT_DETAILS=detailed
          CREATE_LOG_FILE=true
          
          ##########################
          # File Filtering
          ##########################
          
          # Filter settings
          USE_FIND_ALGORITHM=false
          IGNORE_GITIGNORED_FILES=true
          
          ##########################
          # Suppression
          ##########################
          
          # Suppress certain outputs for cleaner logs
          SUPPRESS_POSSUM=true
          SUPPRESS_FILE_TYPE_WARN=true
          ENVEOF
          
          # Replace placeholders with actual values
          sed -i "s/BRANCH_PLACEHOLDER/${{ steps.config.outputs.default_branch }}/g" .github/super-linter-dynamic.env
          sed -i "s/VALIDATE_ALL_PLACEHOLDER/${validate_all_codebase}/g" .github/super-linter-dynamic.env
          sed -i "s/YAML_PLACEHOLDER/${yaml_validation}/g" .github/super-linter-dynamic.env
          sed -i "s/ANSIBLE_PLACEHOLDER/${ansible_validation}/g" .github/super-linter-dynamic.env
          sed -i "s/MARKDOWN_PLACEHOLDER/${markdown_validation}/g" .github/super-linter-dynamic.env
          sed -i "s/PYTHON_PLACEHOLDER/${python_validation}/g" .github/super-linter-dynamic.env
          sed -i "s/BASH_PLACEHOLDER/${shell_validation}/g" .github/super-linter-dynamic.env
          sed -i "s/JSON_PLACEHOLDER/${json_validation}/g" .github/super-linter-dynamic.env
          sed -i "s/SHELL_PLACEHOLDER/${shell_validation}/g" .github/super-linter-dynamic.env
          sed -i "s/GITHUB_ACTIONS_PLACEHOLDER/${github_actions_validation}/g" .github/super-linter-dynamic.env
          sed -i "s/FIX_YAML_PLACEHOLDER/${yaml_validation}/g" .github/super-linter-dynamic.env
          sed -i "s/FIX_MARKDOWN_PLACEHOLDER/${markdown_validation}/g" .github/super-linter-dynamic.env
          sed -i "s/FIX_JSON_PLACEHOLDER/${json_validation}/g" .github/super-linter-dynamic.env
          sed -i "s/FIX_SHELL_PLACEHOLDER/${shell_validation}/g" .github/super-linter-dynamic.env
          
          echo "âœ… Dynamic configuration generated with intelligent validation"
          echo "ğŸ“‹ Configuration preview:"
          head -20 .github/super-linter-dynamic.env
          echo ""
          echo "ğŸ¯ Validation summary:"
          echo "  - YAML validation: ${yaml_validation} (files: ${{ steps.detect-files.outputs.yaml_files }})"
          echo "  - Ansible validation: ${ansible_validation} (files: ${{ steps.detect-files.outputs.ansible_files }})"
          echo "  - Markdown validation: ${markdown_validation} (files: ${{ steps.detect-files.outputs.markdown_files }})"
          echo "  - Python validation: ${python_validation} (files: ${{ steps.detect-files.outputs.python_files }})"
          echo "  - Shell validation: ${shell_validation} (files: ${{ steps.detect-files.outputs.shell_files }})"

      - name: ğŸ” Run Super Linter
        id: super-linter
        uses: super-linter/super-linter@v5
        env:
          # Use dynamically generated configuration
          ENV_FILE: .github/super-linter-dynamic.env
          
          # GitHub token (required for API access)
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: ğŸ“Š Analyze Auto-fixes Applied
        if: always()
        id: autofix-analysis
        run: |
          echo "ğŸ” Analyzing auto-fixes applied by Super Linter..."

          # Initialize counters
          total_fixes=0
          yaml_fixes=0
          ansible_fixes=0
          python_fixes=0
          shell_fixes=0
          markdown_fixes=0
          json_fixes=0

          # Function to count fixes in git diff
          count_file_changes() {
            local file_pattern="$1"
            local category="$2"

            if git diff --name-only | grep -E "$file_pattern" > /dev/null 2>&1; then
              local changed_files=$(git diff --name-only | grep -E "$file_pattern" | wc -l)
              local total_changes=$(git diff --numstat | grep -E "$file_pattern" | awk '{sum += $1 + $2} END {print sum+0}')

              echo "ğŸ“ $category fixes: $changed_files files, $total_changes changes"
              return $total_changes
            else
              echo "ğŸ“ $category fixes: 0 files, 0 changes"
              return 0
            fi
          }

          # Check if there are any changes from auto-fix
          if git diff --quiet; then
            echo "âœ… No auto-fixes were needed - code already compliant!"
            echo "autofix_needed=false" >> $GITHUB_OUTPUT
            echo "total_fixes=0" >> $GITHUB_OUTPUT
          else
            echo "ğŸ”§ Auto-fixes were applied!"
            echo "autofix_needed=true" >> $GITHUB_OUTPUT

            # Count fixes by category
            count_file_changes "\\.ya?ml$" "YAML"; yaml_fixes=$?
            count_file_changes "\\.py$" "Python"; python_fixes=$?
            count_file_changes "\\.sh$" "Shell/Bash"; shell_fixes=$?
            count_file_changes "\\.md$" "Markdown"; markdown_fixes=$?
            count_file_changes "\\.json$" "JSON"; json_fixes=$?

            # Special handling for Ansible (subset of YAML)
            if git diff --name-only | grep -E "(playbook|tasks|handlers|vars).*\\.ya?ml$|site\\.ya?ml$" > /dev/null 2>&1; then
              ansible_fixes=$(git diff --numstat | grep -E "(playbook|tasks|handlers|vars).*\\.ya?ml$|site\\.ya?ml$" | awk '{sum += $1 + $2} END {print sum+0}')
              echo "ğŸ“ Ansible fixes: $ansible_fixes changes"
            fi

            total_fixes=$((yaml_fixes + python_fixes + shell_fixes + markdown_fixes + json_fixes))

            # Output for next steps
            echo "total_fixes=$total_fixes" >> $GITHUB_OUTPUT
            echo "yaml_fixes=$yaml_fixes" >> $GITHUB_OUTPUT
            echo "ansible_fixes=$ansible_fixes" >> $GITHUB_OUTPUT
            echo "python_fixes=$python_fixes" >> $GITHUB_OUTPUT
            echo "shell_fixes=$shell_fixes" >> $GITHUB_OUTPUT
            echo "markdown_fixes=$markdown_fixes" >> $GITHUB_OUTPUT
            echo "json_fixes=$json_fixes" >> $GITHUB_OUTPUT

            # Show detailed diff summary
            echo ""
            echo "ğŸ“‹ Detailed changes by file:"
            git diff --name-status | while read status file; do
              if [ "$status" = "M" ]; then
                changes=$(git diff --numstat "$file" | awk '{print $1 + $2}')
                echo "  ğŸ“„ $file: $changes changes"
              fi
            done
          fi

      - name: ğŸ’¾ Commit Auto-fixes
        if: steps.autofix-analysis.outputs.autofix_needed == 'true'
        run: |
          echo "ğŸ’¾ Committing auto-fixes..."

          # Configure git (use GitHub Actions bot)
          git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          # Add all changes
          git add .

          # Create detailed commit message
          commit_msg="ğŸ¤– Auto-fix: Applied ${{ steps.autofix-analysis.outputs.total_fixes }} linting fixes

          Auto-fixes applied by Super Linter:
          - YAML fixes: ${{ steps.autofix-analysis.outputs.yaml_fixes }}
          - Ansible fixes: ${{ steps.autofix-analysis.outputs.ansible_fixes }}
          - Python fixes: ${{ steps.autofix-analysis.outputs.python_fixes }}
          - Shell fixes: ${{ steps.autofix-analysis.outputs.shell_fixes }}
          - Markdown fixes: ${{ steps.autofix-analysis.outputs.markdown_fixes }}
          - JSON fixes: ${{ steps.autofix-analysis.outputs.json_fixes }}

          Automated by: ${{ github.workflow }} #${{ github.run_number }}
          Triggered by: ${{ github.event_name }} on ${{ github.ref_name }}"

          # Commit changes
          git commit -m "$commit_msg"

          # Push changes back to the branch
          git push origin ${{ github.ref_name }}

          echo "âœ… Auto-fixes committed and pushed!"

      - name: ğŸ§¹ Sanitize Super Linter Logs
        if: always()
        run: |
          echo "ğŸ§¹ Starting log sanitization process..."
          
          # Check if log file exists and sanitize it
          if [ -f "super-linter.log" ]; then
            echo "âœ… Super Linter log file found: $(ls -la super-linter.log)"
            echo "ğŸ“Š Original log file size: $(wc -l < super-linter.log) lines, $(du -h super-linter.log | cut -f1) size"

            # Create a backup
            cp super-linter.log super-linter.log.original
            echo "âœ… Backup created: $(ls -la super-linter.log.original)"

            # Enhanced masking - Remove or mask potential sensitive patterns
            echo "ğŸ­ Applying comprehensive masking rules..."
            
            # GitHub token patterns (various formats)
            sed -i 's/ghp_[a-zA-Z0-9]\{36\}/***GITHUB_TOKEN***/g' super-linter.log
            sed -i 's/gho_[a-zA-Z0-9]\{36\}/***GITHUB_TOKEN***/g' super-linter.log
            sed -i 's/ghu_[a-zA-Z0-9]\{36\}/***GITHUB_TOKEN***/g' super-linter.log
            sed -i 's/ghs_[a-zA-Z0-9]\{36\}/***GITHUB_TOKEN***/g' super-linter.log
            sed -i 's/github_pat_[a-zA-Z0-9_]\{82\}/***GITHUB_PAT***/g' super-linter.log
            
            # Atlassian/Confluence tokens
            sed -i 's/ATATT[a-zA-Z0-9+/=]\{40,\}/***ATLASSIAN_TOKEN***/g' super-linter.log
            sed -i 's/ATCTT[a-zA-Z0-9+/=]\{40,\}/***ATLASSIAN_TOKEN***/g' super-linter.log
            sed -i 's/ATBT[a-zA-Z0-9+/=]\{40,\}/***ATLASSIAN_TOKEN***/g' super-linter.log
            
            # Authentication headers and tokens
            sed -i 's/Basic [a-zA-Z0-9+/=]\{20,\}/Basic ***ENCODED_CREDENTIALS***/g' super-linter.log
            sed -i 's/Bearer [a-zA-Z0-9+/=]\{20,\}/Bearer ***TOKEN***/g' super-linter.log
            sed -i 's/Authorization: [^[:space:]]\+/Authorization: ***MASKED***/g' super-linter.log
            
            # API keys and secrets (various patterns)
            sed -i 's/[aA][pP][iI][_-][kK][eE][yY][_-]*[:=][[:space:]]*['\''"][a-zA-Z0-9+/=]\{20,\}['\''"]*/API_KEY: ***MASKED***/g' super-linter.log
            sed -i 's/[sS][eE][cC][rR][eE][tT][_-]*[:=][[:space:]]*['\''"][a-zA-Z0-9+/=]\{20,\}['\''"]*/SECRET: ***MASKED***/g' super-linter.log
            sed -i 's/[pP][aA][sS][sS][wW][oO][rR][dD][_-]*[:=][[:space:]]*['\''"][a-zA-Z0-9+/=]\{8,\}['\''"]*/PASSWORD: ***MASKED***/g' super-linter.log
            
            # Generic long base64 patterns that could be credentials (but be careful not to mask normal data)
            sed -i 's/[a-zA-Z0-9+/=]\{60,\}/***POTENTIAL_ENCODED_DATA***/g' super-linter.log
            
            # URLs with embedded credentials
            sed -i 's|https://[^:]*:[^@]*@|https://***USER***:***PASS***@|g' super-linter.log
            sed -i 's|http://[^:]*:[^@]*@|http://***USER***:***PASS***@|g' super-linter.log
            
            # Common environment variable patterns that might contain secrets
            sed -i 's/CONFLUENCE_AUTH=[^[:space:]]*/CONFLUENCE_AUTH=***MASKED***/g' super-linter.log
            sed -i 's/CONFLUENCE_URL=[^[:space:]]*/CONFLUENCE_URL=***MASKED***/g' super-linter.log
            sed -i 's/GITHUB_TOKEN=[^[:space:]]*/GITHUB_TOKEN=***MASKED***/g' super-linter.log
            
            # AWS and other cloud provider keys
            sed -i 's/AKIA[0-9A-Z]\{16\}/***AWS_ACCESS_KEY***/g' super-linter.log
            sed -i 's/[0-9a-zA-Z/+]\{40\}/***AWS_SECRET_KEY***/g' super-linter.log
            
            # SSH keys
            sed -i 's/-----BEGIN [A-Z ]*PRIVATE KEY-----.*-----END [A-Z ]*PRIVATE KEY-----/***SSH_PRIVATE_KEY***/g' super-linter.log
            
            echo "âœ… Masking rules applied successfully"
            echo "ğŸ“Š Sanitized log file size: $(wc -l < super-linter.log) lines, $(du -h super-linter.log | cut -f1) size"

            # Verify sanitization by checking for common patterns
            echo "ğŸ” Verifying sanitization effectiveness..."
            potential_leaks=0
            
            # Check for remaining sensitive patterns
            if grep -q "ghp_\|gho_\|ghu_\|ghs_\|github_pat_" super-linter.log; then
              echo "âš ï¸ Warning: Potential GitHub tokens still found"
              potential_leaks=$((potential_leaks + 1))
            fi
            
            if grep -q "ATATT\|ATCTT\|ATBT" super-linter.log; then
              echo "âš ï¸ Warning: Potential Atlassian tokens still found"
              potential_leaks=$((potential_leaks + 1))
            fi
            
            if grep -qE "Bearer [a-zA-Z0-9+/=]{20,}|Basic [a-zA-Z0-9+/=]{20,}" super-linter.log; then
              echo "âš ï¸ Warning: Potential authentication headers still found"
              potential_leaks=$((potential_leaks + 1))
            fi
            
            if [ $potential_leaks -eq 0 ]; then
              echo "âœ… Sanitization verification passed - no obvious sensitive patterns detected"
            else
              echo "âš ï¸ Sanitization verification found $potential_leaks potential issues - please review"
            fi

            # Show a safe sample of sanitized content for debugging
            echo "ğŸ“‹ Sanitized log sample (first 20 lines, excluding any masked content):"
            head -20 super-linter.log | grep -v "\*\*\*" | head -10 || echo "All sample lines contain masked content"
            
            echo "ğŸ“‹ Sanitized log sample (last 10 lines, excluding any masked content):"
            tail -20 super-linter.log | grep -v "\*\*\*" | head -10 || echo "All sample lines contain masked content"
            
          else
            echo "âŒ Super Linter log file not found"
            echo "ğŸ“‚ Current directory contents:"
            ls -la
            echo "ğŸ“‚ Looking for any log files:"
            find . -name "*.log" -type f 2>/dev/null || echo "No .log files found"
            
            # Create an empty log file so upload doesn't fail
            echo "ğŸ”§ Creating placeholder log file for upload"
            echo "Super Linter log file was not generated or not found." > super-linter.log
            echo "This may indicate that Super Linter failed early or encountered an error." >> super-linter.log
            echo "Check the Super Linter step output for more details." >> super-linter.log
            echo "Generated at: $(date)" >> super-linter.log
          fi

      - name: ï¿½ Analyze Linting Rule Violations
        if: always()
        id: rule-analysis
        run: |
          echo "ğŸ” Analyzing linting rule violations..."

          if [ -f "super-linter.log" ]; then
            echo "âœ… Super Linter log file found"
            echo "ğŸ“Š Log file size: $(wc -l < super-linter.log) lines"
            
            # Show sample of log to debug format
            echo "ğŸ” First 10 lines of super-linter.log:"
            head -10 super-linter.log
            echo ""
            echo "ğŸ” Last 10 lines of super-linter.log:"
            tail -10 super-linter.log
            echo ""
            
            # Extract rule violations and count them
            echo "Extracting rule violations from logs..."

            # Create temporary files for processing
            temp_violations="/tmp/violations.txt"
            temp_descriptions="/tmp/descriptions.txt"
            temp_counts="/tmp/rule_counts.txt"

            # Extract lines with rule violations (those ending with [rulename])
            echo "ğŸ” Looking for lines ending with [rulename]..."
            grep -E '\[[a-zA-Z0-9_-]+\]$' super-linter.log > "$temp_violations" || echo "No rule violations found in specific format"
            
            if [ -s "$temp_violations" ]; then
              echo "âœ… Found $(wc -l < "$temp_violations") violation lines"
              echo "ğŸ” Sample violations found:"
              head -3 "$temp_violations"
              echo ""
            else
              echo "âŒ No violations found in expected format"
              echo "ğŸ” Searching for alternative patterns..."
              echo "Lines containing 'shellcheck':"
              grep -i "shellcheck" super-linter.log | head -3 || echo "None found"
              echo "Lines containing 'actionlint':"
              grep -i "actionlint" super-linter.log | head -3 || echo "None found"
              echo "Lines containing any brackets:"
              grep '\[.*\]' super-linter.log | head -3 || echo "None found"
              echo ""
            fi

            if [ -s "$temp_violations" ]; then
              echo "Processing violation details..."

              # Process each violation to extract linter, description, and rule
              while IFS= read -r line; do
                # Extract the rule/linter name (last item in brackets)
                rule=$(echo "$line" | sed -E 's/.*\[([a-zA-Z0-9_-]+)\]$/\1/')
                
                # Extract the description - different patterns for different linters
                if [[ "$line" == *"shellcheck reported issue"* ]]; then
                  # For shellcheck: extract description after the rule code
                  description=$(echo "$line" | sed -E 's/.*SC[0-9]+:[^:]+:[^:]+:[^:]+: ([^[]+) \[shellcheck\]$/\1/' | sed 's/^ *//' | sed 's/ *$//')
                  linter="shellcheck"
                elif [[ "$line" == *"expression"* ]]; then
                  # For actionlint expression warnings
                  description=$(echo "$line" | sed -E 's/^[^:]*:[^:]*:[^:]*: ([^[]+) \[expression\]$/\1/' | sed 's/^ *//' | sed 's/ *$//')
                  linter="actionlint"
                else
                  # For other linters, try to extract description before the rule
                  description=$(echo "$line" | sed -E 's/^[^:]*:[^:]*:[^:]*: ([^[]+) \[[^]]+\]$/\1/' | sed 's/^ *//' | sed 's/ *$//')
                  linter="$rule"
                fi

                # Clean up description - remove extra whitespace and truncate if too long
                description=$(echo "$description" | sed 's/  */ /g' | cut -c1-80)
                
                # If description extraction failed, use a fallback
                if [[ -z "$description" || "$description" == "$line" ]]; then
                  description="Rule violation detected"
                fi

                # Create a combined key for grouping: linter|description
                echo "${linter}|${description}" >> "$temp_descriptions"
              done < "$temp_violations"

              # Count occurrences of each linter|description combination
              sort "$temp_descriptions" | uniq -c | sort -nr > "$temp_counts"

              # Count total violations
              total_violations=$(wc -l < "$temp_violations")
              unique_rules=$(wc -l < "$temp_counts")

              echo "Found $total_violations total violations across $unique_rules unique rule types"

              # Generate summary for outputs
              echo "total_violations=$total_violations" >> $GITHUB_OUTPUT
              echo "unique_rules=$unique_rules" >> $GITHUB_OUTPUT

              # Create detailed rule breakdown
              echo "violations_found=true" >> $GITHUB_OUTPUT

              # Generate markdown table data
              rules_table=""
              total_count=0
              
              while IFS= read -r line; do
                # Extract count (first field)
                count=$(echo "$line" | awk '{print $1}')
                # Extract everything after the count
                rest=$(echo "$line" | awk '{$1=""; print $0}' | sed 's/^ *//')
                # Split on pipe character
                linter=$(echo "$rest" | cut -d'|' -f1)
                description=$(echo "$rest" | cut -d'|' -f2-)
                
                # Determine severity icon based on linter and patterns
                severity_icon="âš ï¸"
                if [[ "$linter" == "shellcheck" ]]; then
                  if [[ "$description" == *"warning"* ]]; then
                    severity_icon="ğŸŸ¡"
                  elif [[ "$description" == *"error"* ]]; then
                    severity_icon="ğŸ”´"
                  else
                    severity_icon="ğŸ”µ"
                  fi
                elif [[ "$linter" == "actionlint" ]]; then
                  severity_icon="ğŸŸ¡"
                elif [[ "$description" == *"error"* ]] || [[ "$description" == *"security"* ]]; then
                  severity_icon="ğŸ”´"
                elif [[ "$description" == *"warning"* ]] || [[ "$description" == *"style"* ]]; then
                  severity_icon="ğŸŸ¡"
                elif [[ "$description" == *"info"* ]]; then
                  severity_icon="ğŸ”µ"
                fi

                rules_table="$rules_table| $severity_icon **$linter** | $description | $count |\n"
                total_count=$((total_count + count))
              done < "$temp_counts"

              # Add total row
              rules_table="$rules_table| ğŸ“Š **TOTAL** | **All violations** | **$total_count** |\n"

              # Save for use in summary step
              echo -e "$rules_table" > /tmp/rules_table.md

              echo "âœ… Rule analysis completed with detailed descriptions"
            else
              echo "No rule violations found or different log format"
              echo "violations_found=false" >> $GITHUB_OUTPUT
              echo "total_violations=0" >> $GITHUB_OUTPUT
              echo "unique_rules=0" >> $GITHUB_OUTPUT
            fi

            # Clean up temp files
            rm -f "$temp_violations" "$temp_descriptions" "$temp_counts"
          else
            echo "âš ï¸ Super Linter log file not found for analysis"
            echo "violations_found=false" >> $GITHUB_OUTPUT
            echo "total_violations=0" >> $GITHUB_OUTPUT
            echo "unique_rules=0" >> $GITHUB_OUTPUT
          fi

      - name: ğŸ“¤ Upload Sanitized Super Linter Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: super-linter-logs-sanitized-${{ github.run_id }}
          path: super-linter.log
          retention-days: 30
          if-no-files-found: warn

      - name: ğŸ“¤ Upload Original Super Linter Logs (Debug Only)
        if: always() && github.event.inputs.full_scan == 'true'  # Only upload original logs for full scans
        uses: actions/upload-artifact@v4
        with:
          name: super-linter-logs-original-${{ github.run_id }}
          path: super-linter.log.original
          retention-days: 7  # Shorter retention for potentially sensitive logs
          if-no-files-found: warn

      - name: ğŸ“¤ Upload Dynamic Configuration (Debug)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: super-linter-config-${{ github.run_id }}
          path: .github/super-linter-dynamic.env
          retention-days: 7
          if-no-files-found: warn

  # Enhanced security scanning
  security:
    name: ğŸ›¡ï¸ Security Scan
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.any-code-changed == 'true' || inputs.full_scan == true
    permissions:
      actions: read
      contents: read
      security-events: write
    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ” Run DevSkim Scanner
        uses: microsoft/DevSkim-Action@v1

      - name: ğŸ“¤ Upload DevSkim SARIF
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: devskim-results.sarif

      - name: â˜¢ï¸ Run Trivy Vulnerability Scanner
        uses: aquasecurity/trivy-action@0.32.0
        with:
          scan-type: 'fs'
          ignore-unfixed: true
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'

      - name: ğŸ“¤ Upload Trivy Scan Results
        uses: actions/upload-artifact@v4
        with:
          name: trivy-results
          path: trivy-results.sarif
      - name: ğŸ” Advanced Secret Detection
        run: |
          echo "ğŸ” Running security validation..."

          # Check for potential secrets (excluding false positives)
          echo "Checking for potential hardcoded secrets..."
          if grep -rE "(password|secret|api_key|auth_token|private_key):\s*['\"]?[A-Za-z0-9+/=]{10,}" . \
             --include="*.yml" --include="*.yaml" --include="*.py" --include="*.sh" \
             --exclude-dir=.git --exclude-dir=.github \
             --exclude="*example*" --exclude="*template*" \
             | grep -v "YOUR_.*_HERE\|test:test\|example\|template\|#.*token\|#.*secret\|README"; then
            echo "âš ï¸ Potential secrets found - please review"
            exit 1
          else
            echo "âœ… No obvious secrets detected"
          fi

      - name: ğŸ”’ File Permissions Check
        run: |
          echo "ğŸ”’ Checking file permissions..."

          # Check for world-writable files
          if find . -name "*.yml" -o -name "*.yaml" -o -name "*.py" -o -name "*.sh" | xargs ls -la | grep "^-.......rw"; then
            echo "âŒ World-writable files found"
            find . -name "*.yml" -o -name "*.yaml" -o -name "*.py" -o -name "*.sh" | xargs ls -la | grep "^-.......rw"
            exit 1
          else
            echo "âœ… File permissions look secure"
          fi

      - name: ğŸ›¡ï¸ Security Summary
        if: always()
        run: |
          echo "## ğŸ›¡ï¸ Security Validation Summary" >> $GITHUB_STEP_SUMMARY
          echo "âœ… **DevSkim scan completed**" >> $GITHUB_STEP_SUMMARY
          echo "âœ… **Secret detection completed**" >> $GITHUB_STEP_SUMMARY
          echo "âœ… **File permissions checked**" >> $GITHUB_STEP_SUMMARY

  ansible-syntax-check:
    name:  Ansible Syntax Check
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ”§ Set up Python & Install Dependencies
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      - run: |
          python -m pip install --upgrade pip
          pip install ansible-lint # We only need ansible-lint

      - name: ğŸ­ Run Ansible Lint
        id: lint # Give this step an ID to reference its outcome
        run: |
          # This single command lints all files, respects .ansible-lint config,
          # and creates the SARIF report.
          ansible-lint --sarif-file=ansible-results.sarif
        continue-on-error: true # Allow the workflow to continue to the upload step

      - name: ğŸ“¤ Upload Ansible-Lint SARIF Report
        if: always() # Always run this step to upload the report
        uses: actions/upload-artifact@v4
        with:
          name: ansible-lint-results
          path: ansible-results.sarif

      - name: ğŸ“‹ Check Linting Results
        if: steps.lint.outcome == 'failure'
        run: |
          echo "âŒ Ansible-lint found issues."
          exit 1 # Explicitly fail the job if the linting step failed

  publish:
    name: ğŸš€ Publish to Confluence
    # Your conditions for running the job remain the same
    needs: [super-linter, security, ansible-syntax-check]
    if: >
      github.event_name == 'push' &&
      (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/heads/release/') || startsWith(github.ref, 'refs/heads/hotfix/')) &&
      needs.ansible-syntax-check.result == 'success'

    # ğŸ’¡ 1. The 'uses' key now calls your local reusable workflow.
    # The runs-on and steps are removed.
    # Using local workflow instead of external dependency for better reliability.
    uses: ./.github/workflows/publish-docs.yml

    # ğŸ’¡ 2. Pass the required secrets to the reusable workflow.
    secrets:
      CONFLUENCE_URL: ${{ secrets.CONFLUENCE_URL }}
      CONFLUENCE_USER: ${{ secrets.CONFLUENCE_USER }}
      CONFLUENCE_API_TOKEN: ${{ secrets.CONFLUENCE_API_TOKEN }}

# In ci.yml, this replaces all other summary/report jobs

  comprehensive-report:
    name: ğŸ“Š Generate Comprehensive Report
    # This job runs after all checks are complete
    needs: [super-linter, security, ansible-syntax-check]
    if: always() # Always run to report on success or failure
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“¥ Download all artifacts
        uses: actions/download-artifact@v4
        with:
          # Download all artifacts into a 'reports' directory
          path: ./reports
        continue-on-error: true

      - name: ğŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'

      - name: ğŸ“¦ Cache Python Dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: ğŸ”§ Checkout Code (for scripts)
        uses: actions/checkout@v4

      - name: ğŸ“ Generate Summary from All Reports
        run: python scripts/generate_sarif_summary.py