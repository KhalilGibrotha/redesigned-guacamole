---
name: 🚀 CI/CD Pipeline

on:
  # Manual trigger - allows running from GitHub UI
  workflow_dispatch:
    inputs:
      full_scan:
        description: 'Run full codebase scan (not just changed files)'
        required: false
        type: boolean
        default: true
      target_environment:
        description: 'Target environment for publishing'
        required: false
        type: choice
        options:
          - 'production'
          - 'staging'
          - 'development'
        default: 'production'
      dry_run:
        description: 'Dry run mode (no actual publishing)'
        required: false
        type: boolean
        default: false

  # Remote trigger - allows being called by other workflows
  workflow_call:
    inputs:
      full_scan:
        description: 'Run full codebase scan (not just changed files)'
        required: false
        type: boolean
        default: false
      branch_name:
        description: 'Branch name to checkout'
        required: false
        type: string
        default: ''
      target_environment:
        description: 'Target environment for publishing'
        required: false
        type: string
        default: 'production'
      dry_run:
        description: 'Dry run mode (no actual publishing)'
        required: false
        type: boolean
        default: false
    secrets:
      CONFLUENCE_URL:
        required: false
      CONFLUENCE_USER:
        required: false
      CONFLUENCE_API_TOKEN:
        required: false

jobs:
  # Job to detect what types of files have changed for optimized execution
  detect-changes:
    name: 🔍 Detect File Changes
    runs-on: ubuntu-latest
    outputs:
      docs-changed: ${{ steps.final.outputs.docs-changed }}
      ansible-changed: ${{ steps.final.outputs.ansible-changed }}
      python-changed: ${{ steps.final.outputs.python-changed }}
      workflows-changed: ${{ steps.final.outputs.workflows-changed }}
      any-code-changed: ${{ steps.final.outputs.any-code-changed }}
      external-call: ${{ steps.context.outputs.external-call }}
    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ inputs.branch_name || github.ref }}

      - name: 🔍 Check Repository Context
        id: context
        run: |
          echo "Current repository: ${{ github.repository }}"
          echo "Event name: ${{ github.event_name }}"
          echo "Ref: ${{ github.ref }}"
          echo "Ref name: ${{ github.ref_name }}"

          # Detect external calls via workflow_call event
          # When called externally via workflow_call, we assume all changes for simplicity
          if [[ "${{ github.event_name }}" == "workflow_call" ]]; then
            echo "external-call=true" >> $GITHUB_OUTPUT
            echo "🔄 External workflow call detected (workflow_call event) - will assume docs changed"
          else
            echo "external-call=false" >> $GITHUB_OUTPUT
            echo "🏠 Internal repository call - will detect actual changes"
          fi

      - name: 🔍 Detect Changes
        uses: dorny/paths-filter@v2
        if: steps.context.outputs.external-call != 'true'
        id: changes
        with:
          filters: |
            docs:
              - 'docs/**'
              - 'templates/**'
              - 'vars/**'
              - '*.md'
              - '*.j2'
            ansible:
              - 'playbooks/**'
              - 'inventory/**'
              - '*.yml'
              - '*.yaml'
            python:
              - '**/*.py'
              - 'requirements.txt'
            workflows:
              - '.github/**'
            code:
              - '**/*.py'
              - '**/*.yml'
              - '**/*.yaml'
              - '**/*.j2'
              - '**/*.md'

      - name: 🔄 Set Default Outputs
        id: defaults
        if: steps.context.outputs.external-call != 'true' && steps.changes.outcome != 'success'
        run: |
          echo "docs=false" >> $GITHUB_OUTPUT
          echo "ansible=false" >> $GITHUB_OUTPUT
          echo "python=false" >> $GITHUB_OUTPUT
          echo "workflows=false" >> $GITHUB_OUTPUT
          echo "code=false" >> $GITHUB_OUTPUT

      - name: 🔄 Set External Changes
        id: external
        if: steps.context.outputs.external-call == 'true'
        run: |
          echo "🔄 External call detected - assuming all changes"
          echo "docs-changed=true" >> $GITHUB_OUTPUT
          echo "ansible-changed=true" >> $GITHUB_OUTPUT
          echo "python-changed=true" >> $GITHUB_OUTPUT
          echo "workflows-changed=true" >> $GITHUB_OUTPUT
          echo "any-code-changed=true" >> $GITHUB_OUTPUT

      - name: 🔄 Set Internal Changes
        id: internal
        if: steps.context.outputs.external-call != 'true'
        run: |
          echo "🏠 Internal call - using actual change detection"
          echo "docs-changed=${{ steps.changes.outputs.docs || 'false' }}" >> $GITHUB_OUTPUT
          echo "ansible-changed=${{ steps.changes.outputs.ansible || 'false' }}" >> $GITHUB_OUTPUT
          echo "python-changed=${{ steps.changes.outputs.python || 'false' }}" >> $GITHUB_OUTPUT
          echo "workflows-changed=${{ steps.changes.outputs.workflows || 'false' }}" >> $GITHUB_OUTPUT
          echo "any-code-changed=${{ steps.changes.outputs.code || 'false' }}" >> $GITHUB_OUTPUT

      - name: 🔄 Finalize Change Detection
        id: final
        run: |
          # Use outputs from the step that actually ran
          if [[ "${{ steps.context.outputs.external-call }}" == "true" ]]; then
            echo "docs-changed=${{ steps.external.outputs.docs-changed }}" >> $GITHUB_OUTPUT
            echo "ansible-changed=${{ steps.external.outputs.ansible-changed }}" >> $GITHUB_OUTPUT
            echo "python-changed=${{ steps.external.outputs.python-changed }}" >> $GITHUB_OUTPUT
            echo "workflows-changed=${{ steps.external.outputs.workflows-changed }}" >> $GITHUB_OUTPUT
            echo "any-code-changed=${{ steps.external.outputs.any-code-changed }}" >> $GITHUB_OUTPUT
          else
            echo "docs-changed=${{ steps.internal.outputs.docs-changed }}" >> $GITHUB_OUTPUT
            echo "ansible-changed=${{ steps.internal.outputs.ansible-changed }}" >> $GITHUB_OUTPUT
            echo "python-changed=${{ steps.internal.outputs.python-changed }}" >> $GITHUB_OUTPUT
            echo "workflows-changed=${{ steps.internal.outputs.workflows-changed }}" >> $GITHUB_OUTPUT
            echo "any-code-changed=${{ steps.internal.outputs.any-code-changed }}" >> $GITHUB_OUTPUT
          fi

      - name: 📊 Debug Publishing Conditions
        run: |
          echo "## 🔍 Publishing Condition Debug" >> $GITHUB_STEP_SUMMARY
          echo "- **Event name**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch reference**: ${{ github.ref }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch name**: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **External call**: ${{ steps.context.outputs.external-call }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Docs changed**: ${{ steps.final.outputs.docs-changed }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Full scan input**: ${{ inputs.full_scan }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Publishing will run if:" >> $GITHUB_STEP_SUMMARY
          echo "1. Event is 'workflow_call/workflow_dispatch' ✅: ${{ github.event_name == 'workflow_call' || github.event_name == 'workflow_dispatch' }}" >> $GITHUB_STEP_SUMMARY
          echo "2. External call OR branch is main/release/hotfix ✅: ${{ steps.context.outputs.external-call == 'true' || github.ref == 'refs/heads/main' ||
            startsWith(github.ref, 'refs/heads/release/') || startsWith(github.ref, 'refs/heads/hotfix/') }}" >> $GITHUB_STEP_SUMMARY
          echo "3. Docs changed OR full_scan OR external call ✅: ${{ steps.final.outputs.docs-changed == 'true' ||
            inputs.full_scan == true || steps.context.outputs.external-call == 'true' }}" >> $GITHUB_STEP_SUMMARY

  super-linter:
    name: 🔍 Super Linter
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.any-code-changed == 'true' || inputs.full_scan == true

    permissions:
      contents: read
      packages: read
      statuses: write
      security-events: write

    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ inputs.branch_name || github.ref }}

      - name: 🔧 Configure Environment
        id: config
        run: |
          # Dynamic branch detection
          if [ "${{ github.event.repository.default_branch }}" != "" ]; then
            echo "default_branch=${{ github.event.repository.default_branch }}" >> $GITHUB_OUTPUT
          else
            echo "default_branch=main" >> $GITHUB_OUTPUT
          fi

      - name: 🔍 Verify Linter Configuration Files
        run: |
          echo "🔍 Checking for linter configuration files..."

          # Check for .ansible-lint
          if [ -f ".ansible-lint" ]; then
            echo "✅ .ansible-lint found ($(wc -l < .ansible-lint) lines)"
            echo "📄 .ansible-lint preview:"
            head -5 .ansible-lint
          else
            echo "❌ .ansible-lint not found"
          fi

          # Check for .yamllint
          if [ -f ".yamllint" ]; then
            echo "✅ .yamllint found ($(wc -l < .yamllint) lines)"
          else
            echo "❌ .yamllint not found"
          fi

          # Check for markdownlint config (prefer .json)
          if [ -f ".markdownlint.json" ]; then
            echo "✅ .markdownlint.json found ($(wc -l < .markdownlint.json) lines)"
          elif [ -f ".markdownlint.yml" ]; then
            echo "✅ .markdownlint.yml found ($(wc -l < .markdownlint.yml) lines)"
          else
            echo "❌ No markdownlint config found"
          fi

          # Check for any conflicting config files
          if [ -f ".markdownlint.json" ] && [ -f ".markdownlint.yml" ]; then
            echo "⚠️  Both .markdownlint.json and .markdownlint.yml found - Super Linter will prefer .json"
          fi

          echo "🎯 Super Linter will auto-detect all configuration files at repo root"

      - name: 🔍 Detect Files for Validation
        id: detect-files
        run: |
          echo "🔍 Detecting file types for intelligent validation..."

          # Check for different file types and set outputs (with proper quoting)
          yaml_files=$(find . -type f \( -name "*.yml" -o -name "*.yaml" \) ! -path "./.git/*" | wc -l)
          ansible_files=$(find . -type f \( -path "./playbooks/*" -o -path "./roles/*" \
            -o -name "site.yml" -o -name "playbook*.yml" -o -name "playbook*.yaml" \) | wc -l)
          python_files=$(find . -type f -name "*.py" ! -path "./.git/*" ! -path "./.venv/*" ! -path "./venv/*" | wc -l)
          markdown_files=$(find . -type f -name "*.md" ! -path "./.git/*" | wc -l)
          shell_files=$(find . -type f -name "*.sh" ! -path "./.git/*" | wc -l)
          json_files=$(find . -type f -name "*.json" ! -path "./.git/*" ! -path "./node_modules/*" | wc -l)
          github_actions_files=$(find .github/workflows -type f \( -name "*.yml" -o -name "*.yaml" \) 2>/dev/null | wc -l)

          # Set outputs
          echo "yaml_files=$yaml_files" >> $GITHUB_OUTPUT
          echo "ansible_files=$ansible_files" >> $GITHUB_OUTPUT
          echo "python_files=$python_files" >> $GITHUB_OUTPUT
          echo "markdown_files=$markdown_files" >> $GITHUB_OUTPUT
          echo "shell_files=$shell_files" >> $GITHUB_OUTPUT
          echo "json_files=$json_files" >> $GITHUB_OUTPUT
          echo "github_actions_files=$github_actions_files" >> $GITHUB_OUTPUT

          # Output summary
          echo "🎯 File detection summary:"
          echo "  - YAML files found: $yaml_files"
          echo "  - Ansible files found: $ansible_files"
          echo "  - Python files found: $python_files"
          echo "  - Markdown files found: $markdown_files"
          echo "  - Shell files found: $shell_files"
          echo "  - JSON files found: $json_files"
          echo "  - GitHub Actions files found: $github_actions_files"
          echo ""
          echo "📋 Linters that will be enabled based on file detection:"
          [ "$yaml_files" -gt 0 ] && echo "  ✅ YAML/yamllint"
          [ "$ansible_files" -gt 0 ] && echo "  ✅ Ansible/ansible-lint"
          [ "$markdown_files" -gt 0 ] && echo "  ✅ Markdown/markdownlint"
          [ "$python_files" -gt 0 ] && echo "  ✅ Python/flake8"
          [ "$shell_files" -gt 0 ] && echo "  ✅ Shell/ShellCheck"
          [ "$json_files" -gt 0 ] && echo "  ✅ JSON/jsonlint"
          [ "$github_actions_files" -gt 0 ] && echo "  ✅ GitHub Actions/actionlint"

      - name: 🔍 Verify Configuration Files
        run: |
          echo "🔍 Verifying Super Linter configuration..."
          echo "Static configuration file contents:"
          cat .github/super-linter.env
          echo ""
          echo "🔍 Verifying yamllint configuration:"
          if [ -f ".yamllint" ]; then
            echo "✅ .yamllint file exists"
            echo "📄 .yamllint line-length configuration:"
            grep -A 10 "line-length:" .yamllint || echo "❌ line-length not found in .yamllint"
          else
            echo "❌ .yamllint file not found"
          fi

      - name: 🔍 Run Super Linter
        id: super-linter
        uses: super-linter/super-linter@v5
        env:
          # Use static configuration file
          ENV_FILE: .github/super-linter.env

          # GitHub token (required for API access)
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

          # Branch and validation settings
          DEFAULT_BRANCH: ${{ steps.config.outputs.default_branch }}
          VALIDATE_ALL_CODEBASE: ${{ inputs.full_scan == true }}

      - name: � Enhanced Super Linter Analysis
        if: always()
        id: enhanced-analysis
        run: |
          echo "::group::🔍 Enhanced Super Linter Analysis"

          # Run comprehensive analysis that includes autofix detection
          echo "� Running enhanced code quality analysis..."
          python3 scripts/enhanced_linter_analysis.py

          echo "✅ Enhanced analysis completed"
          echo "::endgroup::"
        working-directory: ${{ github.workspace }}

      - name: 💾 Commit Auto-fixes
        if: steps.enhanced-analysis.outputs.autofix_needed == 'true' && github.event_name != 'workflow_call'
        run: |
          echo "💾 Committing auto-fixes..."

          # Configure git (use GitHub Actions bot)
          git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          # Add all changes
          git add .

          # Create detailed commit message
          commit_msg="🤖 Auto-fix: Applied ${{ steps.enhanced-analysis.outputs.total_fixes }} linting fixes

          Auto-fixes applied by Super Linter:
          - YAML fixes: ${{ steps.enhanced-analysis.outputs.yaml_fixes }}
          - Ansible fixes: ${{ steps.enhanced-analysis.outputs.ansible_fixes }}
          - Python fixes: ${{ steps.enhanced-analysis.outputs.python_fixes }}
          - Shell fixes: ${{ steps.enhanced-analysis.outputs.shell_fixes }}
          - Markdown fixes: ${{ steps.enhanced-analysis.outputs.markdown_fixes }}
          - JSON fixes: ${{ steps.enhanced-analysis.outputs.json_fixes }}

          Automated by: ${{ github.workflow }} #${{ github.run_number }}
          Health Score: ${{ steps.enhanced-analysis.outputs.overall_health_score }}/100"

          # Commit changes
          git commit -m "$commit_msg"

          # Push changes back to the branch
          git push origin ${{ github.ref_name }}

          echo "✅ Auto-fixes committed and pushed!"

      - name: ⚠️ Auto-fix Skipped (External Call)
        if: steps.enhanced-analysis.outputs.autofix_needed == 'true' && github.event_name == 'workflow_call'
        run: |
          echo "⚠️ Auto-fixes detected but skipped for external workflow calls"
          echo "🔍 Found ${{ steps.enhanced-analysis.outputs.total_fixes }} potential fixes:"
          echo "  - YAML fixes: ${{ steps.enhanced-analysis.outputs.yaml_fixes }}"
          echo "  - Ansible fixes: ${{ steps.enhanced-analysis.outputs.ansible_fixes }}"
          echo "  - Python fixes: ${{ steps.enhanced-analysis.outputs.python_fixes }}"
          echo "  - Shell fixes: ${{ steps.enhanced-analysis.outputs.shell_fixes }}"
          echo "  - Markdown fixes: ${{ steps.enhanced-analysis.outputs.markdown_fixes }}"
          echo "  - JSON fixes: ${{ steps.enhanced-analysis.outputs.json_fixes }}"
          echo ""
          echo "💡 To apply these fixes, run the workflow directly on the target repository"

      - name: 📤 Upload Super Linter Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: super-linter-logs-${{ github.run_id }}
          path: |
            super-linter.log
            github-super-linter.log
            .github/super-linter.env
          retention-days: 30
          if-no-files-found: ignore

      - name: 📤 Upload Static Configuration (Debug)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: super-linter-config-${{ github.run_id }}
          path: .github/super-linter.env
          retention-days: 7
          if-no-files-found: warn

  # Enhanced security scanning - only runs when code changes
  security:
    name: 🛡️ Security Scan
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.any-code-changed == 'true' || inputs.full_scan == true
    permissions:
      actions: read
      contents: read
      security-events: write
    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.branch_name || github.ref }}

      - name: 🔍 Run DevSkim Scanner
        uses: microsoft/DevSkim-Action@v1

      - name: 📤 Upload DevSkim SARIF
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: devskim-results.sarif

      - name: ☢️ Run Trivy Vulnerability Scanner
        uses: aquasecurity/trivy-action@0.32.0
        with:
          scan-type: 'fs'
          ignore-unfixed: true
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'

      - name: 📤 Upload Trivy Scan Results
        uses: actions/upload-artifact@v4
        with:
          name: trivy-results
          path: trivy-results.sarif

      - name: 🔐 Advanced Secret Detection
        run: |
          echo "🔍 Running security validation..."

          # Check for potential secrets (excluding false positives)
          echo "Checking for potential hardcoded secrets..."
          if grep -rE "(password|secret|api_key|auth_token|private_key):\s*['\"]?[A-Za-z0-9+/=]{10,}" . \
             --include="*.yml" --include="*.yaml" --include="*.py" --include="*.sh" \
             --exclude-dir=.git --exclude-dir=.github \
             --exclude="*example*" --exclude="*template*" \
             | grep -v "YOUR_.*_HERE\|test:test\|example\|template\|#.*token\|#.*secret\|README"; then
            echo "⚠️ Potential secrets found - please review"
            exit 1
          else
            echo "✅ No obvious secrets detected"
          fi

      - name: 🔒 File Permissions Check
        run: |
          echo "🔒 Checking file permissions..."

          # Check for world-writable files
          if find . -name "*.yml" -o -name "*.yaml" -o -name "*.py" -o -name "*.sh" | xargs ls -la | grep "^-.......rw"; then
            echo "❌ World-writable files found"
            find . -name "*.yml" -o -name "*.yaml" -o -name "*.py" -o -name "*.sh" | xargs ls -la | grep "^-.......rw"
            exit 1
          else
            echo "✅ File permissions look secure"
          fi

      - name: 🛡️ Security Summary
        if: always()
        run: |
          echo "## 🛡️ Security Validation Summary" >> $GITHUB_STEP_SUMMARY
          echo "✅ **DevSkim scan completed**" >> $GITHUB_STEP_SUMMARY
          echo "✅ **Secret detection completed**" >> $GITHUB_STEP_SUMMARY
          echo "✅ **File permissions checked**" >> $GITHUB_STEP_SUMMARY

  # Publish job - runs on main/release/hotfix branches when docs change, regardless of linting results
  publish:
    name: 🚀 Publish to Confluence

    # Use relative path for better compatibility with external calls
    uses: ./.github/workflows/publish-docs.yml
    with:
      target_environment: ${{ inputs.target_environment || 'production' }}
      dry_run: ${{ inputs.dry_run || false }}
      full_scan: ${{ inputs.full_scan }}

    # Pass the required secrets to the reusable workflow.
    secrets:
      CONFLUENCE_URL: ${{ secrets.CONFLUENCE_URL }}
      CONFLUENCE_USER: ${{ secrets.CONFLUENCE_USER }}
      CONFLUENCE_API_TOKEN: ${{ secrets.CONFLUENCE_API_TOKEN }}

  # Comprehensive report - always runs to provide summary
  comprehensive-report:
    name: 📊 Generate Comprehensive Report
    # This job runs after all checks are complete, including publish which now runs in parallel
    needs: [super-linter, security, detect-changes, publish]
    if: always()  # Always run to report on success or failure
    runs-on: ubuntu-latest
    steps:
      - name: � Checkout Code (for scripts)
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.branch_name || github.ref }}

      - name: �📥 Download all artifacts
        uses: actions/download-artifact@v4
        with:
          # Download all artifacts into a 'reports' directory
          path: ./reports
        continue-on-error: true

      - name: 🐍 Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'

      - name: 📦 Install Dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi

      - name: 📝 Generate SARIF Security Reports Summary
        if: always()
        run: |
          python3 -c "
          import json
          import os
          import glob
          import sys

          def parse_sarif(file_path):
              if not os.path.exists(file_path):
                  return '| N/A | No report found | This scan may have failed to produce a report. | N/A |\n', 0

              report_md = ''
              results = {}
              total_issues = 0

              try:
                  with open(file_path, 'r', encoding='utf-8') as f:
                      sarif_data = json.load(f)
                      for run in sarif_data.get('runs', []):
                          for result in run.get('results', []):
                              total_issues += 1
                              rule_id = result.get('ruleId', 'unknown')
                              message = result.get('message', {}).get('text', 'No description available')
                              level = result.get('level', 'warning').upper()
                              key = (level, rule_id, message)
                              results[key] = results.get(key, 0) + 1
              except (json.JSONDecodeError, KeyError, TypeError) as e:
                  return f'| ERROR | PARSE_ERROR | Failed to parse SARIF file: {str(e)} | N/A |\n', 0

              if not results:
                  report_md += '| ✅ | None | No issues found! | 0 |\n'
              else:
                  for (level, rule, msg), count in sorted(results.items()):
                      msg_escaped = msg.replace('|', '\\|').replace('\n', ' ').replace('\r', '').replace('`', '\\`')
                      report_md += f'| {level} | \`{rule}\` | {msg_escaped} | {count} |\n'

              return report_md, total_issues

          # Main execution
          summary_file = os.getenv('GITHUB_STEP_SUMMARY')
          if not summary_file:
              print('ERROR: GITHUB_STEP_SUMMARY environment variable not set', file=sys.stderr)
              sys.exit(1)

          reports_dir = './reports'
          overall_total = 0

          # Dynamically discover all SARIF reports
          all_reports = {}
          for p in glob.glob(os.path.join(reports_dir, '**', '*.sarif'), recursive=True):
              name = os.path.basename(os.path.dirname(p)).replace('-', ' ').replace('_', ' ').title()
              if name:
                  all_reports[name] = p

          print(f'Processing {len(all_reports)} report types...')
          print(f'Reports directory: {reports_dir}')
          print(f'Summary will be written to: {summary_file}')

          # Check if reports directory exists
          if not os.path.exists(reports_dir):
              print(f'WARNING: Reports directory {reports_dir} does not exist')
              print('This is normal if no artifacts were generated or downloaded.')
              with open(summary_file, 'a') as f:
                  f.write('## 📊 Security & Quality Reports Summary\n\n')
                  f.write('### ⚠️ No Reports Found\n\n')
                  f.write('The reports directory was not found. This may indicate:\n')
                  f.write('- No artifacts were generated by the scanning jobs\n')
                  f.write('- All scans passed without issues (no SARIF files created)\n')
                  f.write('- Artifact download failed or was skipped\n\n')
                  f.write('**This is often normal** - it means no security or linting issues were detected!\n\n')
              print('✅ Summary generated with no reports found message')
              sys.exit(0)

          # Check if directory is empty
          all_files = glob.glob(os.path.join(reports_dir, '**', '*'), recursive=True)
          report_files = [f for f in all_files if f.endswith('.sarif')]

          if not report_files:
              print(f'INFO: Reports directory exists but contains no SARIF files')
              print(f'Found {len(all_files)} total files in reports directory')
              with open(summary_file, 'a') as f:
                  f.write('## 📊 Security & Quality Reports Summary\n\n')
                  f.write('### ✅ No Issues Found\n\n')
                  f.write('Reports directory exists but no SARIF reports were found.\n')
                  f.write('This typically means all security and linting scans passed successfully!\n\n')
                  if len(all_files) > 0:
                      f.write(f'📁 **Files found in reports directory**: {len(all_files)}\n')
                      f.write('(These may be log files or other artifacts)\n\n')
              print('✅ Summary generated with no issues found message')
              sys.exit(0)

          # Process each report
          with open(summary_file, 'a') as f:
              f.write('## 📊 Security & Quality Reports Summary\n\n')

          for tool_name, report_path in all_reports.items():
              print(f'Processing {tool_name} report: {report_path}')

              with open(summary_file, 'a') as f:
                  f.write(f'### {tool_name} Report\n')
                  f.write('| Severity | Rule ID | Description | Total |\n')
                  f.write('|----------|---------|-------------|-------|\n')

              report_content, issue_count = parse_sarif(report_path)
              overall_total += issue_count

              with open(summary_file, 'a') as f:
                  f.write(report_content)
                  f.write('\n')

              print(f'  - Found {issue_count} issues in {tool_name}')

          # Final summary
          with open(summary_file, 'a') as f:
              f.write('\n---\n\n')
              if overall_total == 0:
                  f.write('### 🎉 Excellent! No Issues Found\n\n')
                  f.write('All security and quality scans completed successfully with no issues detected.\n')
              else:
                  f.write(f'### 📊 Total Issues Found: {overall_total}\n\n')
                  f.write('Please review the individual reports above for detailed information.\n')

          print(f'✅ Summary generation complete. Total issues across all tools: {overall_total}')
          "

      - name: 📊 Execution Summary
        if: always()
        run: |
          echo "## 🚀 Workflow Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🔍 Change Detection Results" >> $GITHUB_STEP_SUMMARY
          echo "- **Repository**: ${{ github.repository }}" >> $GITHUB_STEP_SUMMARY
          echo "- **External call**: ${{ needs.detect-changes.outputs.external-call }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Documentation changed**: ${{ needs.detect-changes.outputs.docs-changed }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Ansible files changed**: ${{ needs.detect-changes.outputs.ansible-changed }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Python files changed**: ${{ needs.detect-changes.outputs.python-changed }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Workflow files changed**: ${{ needs.detect-changes.outputs.workflows-changed }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Any code changed**: ${{ needs.detect-changes.outputs.any-code-changed }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📊 Job Execution Status" >> $GITHUB_STEP_SUMMARY
          echo "- **Super Linter**: ${{ needs.super-linter.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Security Scan**: ${{ needs.security.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Publishing**: ${{ needs.publish.result || 'skipped (no docs changes or not main branch)' }}" >> $GITHUB_STEP_SUMMARY
