---
name: 🚀 CI/CD Pipeline

on:
  workflow_call:
    inputs:
      full_scan:
        description: 'Run full codebase scan (not just changed files)'
        required: false
        type: boolean
        default: true
      branch_name:
        description: 'Branch name to checkout'
        required: false
        type: string
        default: ''
    secrets:
      CONFLUENCE_URL:
        required: false
      CONFLUENCE_USER:
        required: false
      CONFLUENCE_API_TOKEN:
        required: false

jobs:
  super-linter:
    name: 🔍 Super Linter
    runs-on: ubuntu-latest

    permissions:
      contents: read
      packages: read
      statuses: write
      security-events: write

    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: 🔧 Configure Environment
        id: config
        run: |
          # Dynamic branch detection
          if [ "${{ github.event.repository.default_branch }}" != "" ]; then
            echo "default_branch=${{ github.event.repository.default_branch }}" >> $GITHUB_OUTPUT
          else
            echo "default_branch=main" >> $GITHUB_OUTPUT
          fi

      - name: 🔍 Verify Linter Configuration Files
        run: |
          echo "🔍 Checking for linter configuration files..."

          # Check for .ansible-lint
          if [ -f ".ansible-lint" ]; then
            echo "✅ .ansible-lint found ($(wc -l < .ansible-lint) lines)"
            echo "📄 .ansible-lint preview:"
            head -5 .ansible-lint
          else
            echo "❌ .ansible-lint not found"
          fi

          # Check for .yamllint
          if [ -f ".yamllint" ]; then
            echo "✅ .yamllint found ($(wc -l < .yamllint) lines)"
          else
            echo "❌ .yamllint not found"
          fi

          # Check for markdownlint config (prefer .json)
          if [ -f ".markdownlint.json" ]; then
            echo "✅ .markdownlint.json found ($(wc -l < .markdownlint.json) lines)"
          elif [ -f ".markdownlint.yml" ]; then
            echo "✅ .markdownlint.yml found ($(wc -l < .markdownlint.yml) lines)"
          else
            echo "❌ No markdownlint config found"
          fi

          # Check for any conflicting config files
          if [ -f ".markdownlint.json" ] && [ -f ".markdownlint.yml" ]; then
            echo "⚠️  Both .markdownlint.json and .markdownlint.yml found - Super Linter will prefer .json"
          fi

          echo "🎯 Super Linter will auto-detect all configuration files at repo root"

      - name: 🔍 Run Super Linter
        id: super-linter
        uses: super-linter/super-linter@v5
        env:
          # Use dynamically generated configuration
          ENV_FILE: .github/super-linter-dynamic.env
          
          # GitHub token (required for API access)
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: 📊 Analyze Auto-fixes Applied
        if: always()
        id: autofix-analysis
        run: |
          echo "🔍 Analyzing auto-fixes applied by Super Linter..."

          # Initialize counters
          total_fixes=0
          yaml_fixes=0
          ansible_fixes=0
          python_fixes=0
          shell_fixes=0
          markdown_fixes=0
          json_fixes=0

          # Function to count fixes in git diff
          count_file_changes() {
            local file_pattern="$1"
            local category="$2"

            if git diff --name-only | grep -E "$file_pattern" > /dev/null 2>&1; then
              local changed_files=$(git diff --name-only | grep -E "$file_pattern" | wc -l)
              local total_changes=$(git diff --numstat | grep -E "$file_pattern" | awk '{sum += $1 + $2} END {print sum+0}')

              echo "📝 $category fixes: $changed_files files, $total_changes changes"
              return $total_changes
            else
              echo "📝 $category fixes: 0 files, 0 changes"
              return 0
            fi
          }

          # Check if there are any changes from auto-fix
          if git diff --quiet; then
            echo "✅ No auto-fixes were needed - code already compliant!"
            echo "autofix_needed=false" >> $GITHUB_OUTPUT
            echo "total_fixes=0" >> $GITHUB_OUTPUT
          else
            echo "🔧 Auto-fixes were applied!"
            echo "autofix_needed=true" >> $GITHUB_OUTPUT

            # Count fixes by category
            count_file_changes "\\.ya?ml$" "YAML"; yaml_fixes=$?
            count_file_changes "\\.py$" "Python"; python_fixes=$?
            count_file_changes "\\.sh$" "Shell/Bash"; shell_fixes=$?
            count_file_changes "\\.md$" "Markdown"; markdown_fixes=$?
            count_file_changes "\\.json$" "JSON"; json_fixes=$?

            # Special handling for Ansible (subset of YAML)
            if git diff --name-only | grep -E "(playbook|tasks|handlers|vars).*\\.ya?ml$|site\\.ya?ml$" > /dev/null 2>&1; then
              ansible_fixes=$(git diff --numstat | grep -E "(playbook|tasks|handlers|vars).*\\.ya?ml$|site\\.ya?ml$" | awk '{sum += $1 + $2} END {print sum+0}')
              echo "📝 Ansible fixes: $ansible_fixes changes"
            fi

            total_fixes=$((yaml_fixes + python_fixes + shell_fixes + markdown_fixes + json_fixes))

            # Output for next steps
            echo "total_fixes=$total_fixes" >> $GITHUB_OUTPUT
            echo "yaml_fixes=$yaml_fixes" >> $GITHUB_OUTPUT
            echo "ansible_fixes=$ansible_fixes" >> $GITHUB_OUTPUT
            echo "python_fixes=$python_fixes" >> $GITHUB_OUTPUT
            echo "shell_fixes=$shell_fixes" >> $GITHUB_OUTPUT
            echo "markdown_fixes=$markdown_fixes" >> $GITHUB_OUTPUT
            echo "json_fixes=$json_fixes" >> $GITHUB_OUTPUT

            # Show detailed diff summary
            echo ""
            echo "📋 Detailed changes by file:"
            git diff --name-status | while read status file; do
              if [ "$status" = "M" ]; then
                changes=$(git diff --numstat "$file" | awk '{print $1 + $2}')
                echo "  📄 $file: $changes changes"
              fi
            done
          fi

      - name: 💾 Commit Auto-fixes
        if: steps.autofix-analysis.outputs.autofix_needed == 'true'
        run: |
          echo "💾 Committing auto-fixes..."

          # Configure git (use GitHub Actions bot)
          git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          # Add all changes
          git add .

          # Create detailed commit message
          commit_msg="🤖 Auto-fix: Applied ${{ steps.autofix-analysis.outputs.total_fixes }} linting fixes

          Auto-fixes applied by Super Linter:
          - YAML fixes: ${{ steps.autofix-analysis.outputs.yaml_fixes }}
          - Ansible fixes: ${{ steps.autofix-analysis.outputs.ansible_fixes }}
          - Python fixes: ${{ steps.autofix-analysis.outputs.python_fixes }}
          - Shell fixes: ${{ steps.autofix-analysis.outputs.shell_fixes }}
          - Markdown fixes: ${{ steps.autofix-analysis.outputs.markdown_fixes }}
          - JSON fixes: ${{ steps.autofix-analysis.outputs.json_fixes }}

          Automated by: ${{ github.workflow }} #${{ github.run_number }}
          Triggered by: ${{ github.event_name }} on ${{ github.ref_name }}"

          # Commit changes
          git commit -m "$commit_msg"

          # Push changes back to the branch
          git push origin ${{ github.ref_name }}

          echo "✅ Auto-fixes committed and pushed!"

      - name: 🧹 Sanitize Super Linter Logs
        if: always()
        run: |
          echo "🧹 Starting log sanitization process..."
          
          # Check if log file exists and sanitize it
          if [ -f "super-linter.log" ]; then
            echo "✅ Super Linter log file found: $(ls -la super-linter.log)"
            echo "📊 Original log file size: $(wc -l < super-linter.log) lines, $(du -h super-linter.log | cut -f1) size"

            # Create a backup
            cp super-linter.log super-linter.log.original
            echo "✅ Backup created: $(ls -la super-linter.log.original)"

            # Enhanced masking - Remove or mask potential sensitive patterns
            echo "🎭 Applying comprehensive masking rules..."
            
            # GitHub token patterns (various formats)
            sed -i 's/ghp_[a-zA-Z0-9]\{36\}/***GITHUB_TOKEN***/g' super-linter.log
            sed -i 's/gho_[a-zA-Z0-9]\{36\}/***GITHUB_TOKEN***/g' super-linter.log
            sed -i 's/ghu_[a-zA-Z0-9]\{36\}/***GITHUB_TOKEN***/g' super-linter.log
            sed -i 's/ghs_[a-zA-Z0-9]\{36\}/***GITHUB_TOKEN***/g' super-linter.log
            sed -i 's/github_pat_[a-zA-Z0-9_]\{82\}/***GITHUB_PAT***/g' super-linter.log
            
            # Atlassian/Confluence tokens
            sed -i 's/ATATT[a-zA-Z0-9+/=]\{40,\}/***ATLASSIAN_TOKEN***/g' super-linter.log
            sed -i 's/ATCTT[a-zA-Z0-9+/=]\{40,\}/***ATLASSIAN_TOKEN***/g' super-linter.log
            sed -i 's/ATBT[a-zA-Z0-9+/=]\{40,\}/***ATLASSIAN_TOKEN***/g' super-linter.log
            
            # Authentication headers and tokens
            sed -i 's/Basic [a-zA-Z0-9+/=]\{20,\}/Basic ***ENCODED_CREDENTIALS***/g' super-linter.log
            sed -i 's/Bearer [a-zA-Z0-9+/=]\{20,\}/Bearer ***TOKEN***/g' super-linter.log
            sed -i 's/Authorization: [^[:space:]]\+/Authorization: ***MASKED***/g' super-linter.log
            
            # API keys and secrets (various patterns)
            sed -i 's/[aA][pP][iI][_-][kK][eE][yY][_-]*[:=][[:space:]]*['\''"][a-zA-Z0-9+/=]\{20,\}['\''"]*/API_KEY: ***MASKED***/g' super-linter.log
            sed -i 's/[sS][eE][cC][rR][eE][tT][_-]*[:=][[:space:]]*['\''"][a-zA-Z0-9+/=]\{20,\}['\''"]*/SECRET: ***MASKED***/g' super-linter.log
            sed -i 's/[pP][aA][sS][sS][wW][oO][rR][dD][_-]*[:=][[:space:]]*['\''"][a-zA-Z0-9+/=]\{8,\}['\''"]*/PASSWORD: ***MASKED***/g' super-linter.log
            
            # Generic long base64 patterns that could be credentials (but be careful not to mask normal data)
            sed -i 's/[a-zA-Z0-9+/=]\{60,\}/***POTENTIAL_ENCODED_DATA***/g' super-linter.log
            
            # URLs with embedded credentials
            sed -i 's|https://[^:]*:[^@]*@|https://***USER***:***PASS***@|g' super-linter.log
            sed -i 's|http://[^:]*:[^@]*@|http://***USER***:***PASS***@|g' super-linter.log
            
            # Common environment variable patterns that might contain secrets
            sed -i 's/CONFLUENCE_AUTH=[^[:space:]]*/CONFLUENCE_AUTH=***MASKED***/g' super-linter.log
            sed -i 's/CONFLUENCE_URL=[^[:space:]]*/CONFLUENCE_URL=***MASKED***/g' super-linter.log
            sed -i 's/GITHUB_TOKEN=[^[:space:]]*/GITHUB_TOKEN=***MASKED***/g' super-linter.log
            
            # AWS and other cloud provider keys
            sed -i 's/AKIA[0-9A-Z]\{16\}/***AWS_ACCESS_KEY***/g' super-linter.log
            sed -i 's/[0-9a-zA-Z/+]\{40\}/***AWS_SECRET_KEY***/g' super-linter.log
            
            # SSH keys
            sed -i 's/-----BEGIN [A-Z ]*PRIVATE KEY-----.*-----END [A-Z ]*PRIVATE KEY-----/***SSH_PRIVATE_KEY***/g' super-linter.log
            
            echo "✅ Masking rules applied successfully"
            echo "📊 Sanitized log file size: $(wc -l < super-linter.log) lines, $(du -h super-linter.log | cut -f1) size"

            # Verify sanitization by checking for common patterns
            echo "🔍 Verifying sanitization effectiveness..."
            potential_leaks=0
            
            # Check for remaining sensitive patterns
            if grep -q "ghp_\|gho_\|ghu_\|ghs_\|github_pat_" super-linter.log; then
              echo "⚠️ Warning: Potential GitHub tokens still found"
              potential_leaks=$((potential_leaks + 1))
            fi
            
            if grep -q "ATATT\|ATCTT\|ATBT" super-linter.log; then
              echo "⚠️ Warning: Potential Atlassian tokens still found"
              potential_leaks=$((potential_leaks + 1))
            fi
            
            if grep -qE "Bearer [a-zA-Z0-9+/=]{20,}|Basic [a-zA-Z0-9+/=]{20,}" super-linter.log; then
              echo "⚠️ Warning: Potential authentication headers still found"
              potential_leaks=$((potential_leaks + 1))
            fi
            
            if [ $potential_leaks -eq 0 ]; then
              echo "✅ Sanitization verification passed - no obvious sensitive patterns detected"
            else
              echo "⚠️ Sanitization verification found $potential_leaks potential issues - please review"
            fi

            # Show a safe sample of sanitized content for debugging
            echo "📋 Sanitized log sample (first 20 lines, excluding any masked content):"
            head -20 super-linter.log | grep -v "\*\*\*" | head -10 || echo "All sample lines contain masked content"
            
            echo "📋 Sanitized log sample (last 10 lines, excluding any masked content):"
            tail -20 super-linter.log | grep -v "\*\*\*" | head -10 || echo "All sample lines contain masked content"
            
          else
            echo "❌ Super Linter log file not found"
            echo "📂 Current directory contents:"
            ls -la
            echo "📂 Looking for any log files:"
            find . -name "*.log" -type f 2>/dev/null || echo "No .log files found"
            
            # Create an empty log file so upload doesn't fail
            echo "🔧 Creating placeholder log file for upload"
            echo "Super Linter log file was not generated or not found." > super-linter.log
            echo "This may indicate that Super Linter failed early or encountered an error." >> super-linter.log
            echo "Check the Super Linter step output for more details." >> super-linter.log
            echo "Generated at: $(date)" >> super-linter.log
          fi

      - name: � Analyze Linting Rule Violations
        if: always()
        id: rule-analysis
        run: |
          echo "🔍 Analyzing linting rule violations..."

          if [ -f "super-linter.log" ]; then
            echo "✅ Super Linter log file found"
            echo "📊 Log file size: $(wc -l < super-linter.log) lines"
            
            # Show sample of log to debug format
            echo "🔍 First 10 lines of super-linter.log:"
            head -10 super-linter.log
            echo ""
            echo "🔍 Last 10 lines of super-linter.log:"
            tail -10 super-linter.log
            echo ""
            
            # Extract rule violations and count them
            echo "Extracting rule violations from logs..."

            # Create temporary files for processing
            temp_violations="/tmp/violations.txt"
            temp_descriptions="/tmp/descriptions.txt"
            temp_counts="/tmp/rule_counts.txt"

            # Extract lines with rule violations (those ending with [rulename])
            echo "🔍 Looking for lines ending with [rulename]..."
            grep -E '\[[a-zA-Z0-9_-]+\]$' super-linter.log > "$temp_violations" || echo "No rule violations found in specific format"
            
            if [ -s "$temp_violations" ]; then
              echo "✅ Found $(wc -l < "$temp_violations") violation lines"
              echo "🔍 Sample violations found:"
              head -3 "$temp_violations"
              echo ""
            else
              echo "❌ No violations found in expected format"
              echo "🔍 Searching for alternative patterns..."
              echo "Lines containing 'shellcheck':"
              grep -i "shellcheck" super-linter.log | head -3 || echo "None found"
              echo "Lines containing 'actionlint':"
              grep -i "actionlint" super-linter.log | head -3 || echo "None found"
              echo "Lines containing any brackets:"
              grep '\[.*\]' super-linter.log | head -3 || echo "None found"
              echo ""
            fi

            if [ -s "$temp_violations" ]; then
              echo "Processing violation details..."

              # Process each violation to extract linter, description, and rule
              while IFS= read -r line; do
                # Extract the rule/linter name (last item in brackets)
                rule=$(echo "$line" | sed -E 's/.*\[([a-zA-Z0-9_-]+)\]$/\1/')
                
                # Extract the description - different patterns for different linters
                if [[ "$line" == *"shellcheck reported issue"* ]]; then
                  # For shellcheck: extract description after the rule code
                  description=$(echo "$line" | sed -E 's/.*SC[0-9]+:[^:]+:[^:]+:[^:]+: ([^[]+) \[shellcheck\]$/\1/' | sed 's/^ *//' | sed 's/ *$//')
                  linter="shellcheck"
                elif [[ "$line" == *"expression"* ]]; then
                  # For actionlint expression warnings
                  description=$(echo "$line" | sed -E 's/^[^:]*:[^:]*:[^:]*: ([^[]+) \[expression\]$/\1/' | sed 's/^ *//' | sed 's/ *$//')
                  linter="actionlint"
                else
                  # For other linters, try to extract description before the rule
                  description=$(echo "$line" | sed -E 's/^[^:]*:[^:]*:[^:]*: ([^[]+) \[[^]]+\]$/\1/' | sed 's/^ *//' | sed 's/ *$//')
                  linter="$rule"
                fi

                # Clean up description - remove extra whitespace and truncate if too long
                description=$(echo "$description" | sed 's/  */ /g' | cut -c1-80)
                
                # If description extraction failed, use a fallback
                if [[ -z "$description" || "$description" == "$line" ]]; then
                  description="Rule violation detected"
                fi

                # Create a combined key for grouping: linter|description
                echo "${linter}|${description}" >> "$temp_descriptions"
              done < "$temp_violations"

              # Count occurrences of each linter|description combination
              sort "$temp_descriptions" | uniq -c | sort -nr > "$temp_counts"

              # Count total violations
              total_violations=$(wc -l < "$temp_violations")
              unique_rules=$(wc -l < "$temp_counts")

              echo "Found $total_violations total violations across $unique_rules unique rule types"

              # Generate summary for outputs
              echo "total_violations=$total_violations" >> $GITHUB_OUTPUT
              echo "unique_rules=$unique_rules" >> $GITHUB_OUTPUT

              # Create detailed rule breakdown
              echo "violations_found=true" >> $GITHUB_OUTPUT

              # Generate markdown table data
              rules_table=""
              total_count=0
              
              while IFS= read -r line; do
                # Extract count (first field)
                count=$(echo "$line" | awk '{print $1}')
                # Extract everything after the count
                rest=$(echo "$line" | awk '{$1=""; print $0}' | sed 's/^ *//')
                # Split on pipe character
                linter=$(echo "$rest" | cut -d'|' -f1)
                description=$(echo "$rest" | cut -d'|' -f2-)
                
                # Determine severity icon based on linter and patterns
                severity_icon="⚠️"
                if [[ "$linter" == "shellcheck" ]]; then
                  if [[ "$description" == *"warning"* ]]; then
                    severity_icon="🟡"
                  elif [[ "$description" == *"error"* ]]; then
                    severity_icon="🔴"
                  else
                    severity_icon="🔵"
                  fi
                elif [[ "$linter" == "actionlint" ]]; then
                  severity_icon="🟡"
                elif [[ "$description" == *"error"* ]] || [[ "$description" == *"security"* ]]; then
                  severity_icon="🔴"
                elif [[ "$description" == *"warning"* ]] || [[ "$description" == *"style"* ]]; then
                  severity_icon="🟡"
                elif [[ "$description" == *"info"* ]]; then
                  severity_icon="🔵"
                fi

                rules_table="$rules_table| $severity_icon **$linter** | $description | $count |\n"
                total_count=$((total_count + count))
              done < "$temp_counts"

              # Add total row
              rules_table="$rules_table| 📊 **TOTAL** | **All violations** | **$total_count** |\n"

              # Save for use in summary step
              echo -e "$rules_table" > /tmp/rules_table.md

              echo "✅ Rule analysis completed with detailed descriptions"
            else
              echo "No rule violations found or different log format"
              echo "violations_found=false" >> $GITHUB_OUTPUT
              echo "total_violations=0" >> $GITHUB_OUTPUT
              echo "unique_rules=0" >> $GITHUB_OUTPUT
            fi

            # Clean up temp files
            rm -f "$temp_violations" "$temp_descriptions" "$temp_counts"
          else
            echo "⚠️ Super Linter log file not found for analysis"
            echo "violations_found=false" >> $GITHUB_OUTPUT
            echo "total_violations=0" >> $GITHUB_OUTPUT
            echo "unique_rules=0" >> $GITHUB_OUTPUT
          fi

      - name: 📤 Upload Sanitized Super Linter Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: super-linter-logs-sanitized-${{ github.run_id }}
          path: super-linter.log
          retention-days: 30
          if-no-files-found: warn

      - name: 📤 Upload Original Super Linter Logs (Debug Only)
        if: always() && github.event.inputs.full_scan == 'true'  # Only upload original logs for full scans
        uses: actions/upload-artifact@v4
        with:
          name: super-linter-logs-original-${{ github.run_id }}
          path: super-linter.log.original
          retention-days: 7  # Shorter retention for potentially sensitive logs
          if-no-files-found: warn

      - name: 📤 Upload Dynamic Configuration (Debug)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: super-linter-config-${{ github.run_id }}
          path: .github/super-linter-dynamic.env
          retention-days: 7
          if-no-files-found: warn

  # Enhanced security scanning
  security:
    name: 🛡️ Security Scan
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
      security-events: write
    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4

      - name: 🔍 Run DevSkim Scanner
        uses: microsoft/DevSkim-Action@v1

      - name: 📤 Upload DevSkim SARIF
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: devskim-results.sarif

      - name: ☢️ Run Trivy Vulnerability Scanner
        uses: aquasecurity/trivy-action@0.32.0
        with:
          scan-type: 'fs'
          ignore-unfixed: true
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'

      - name: 📤 Upload Trivy Scan Results
        uses: actions/upload-artifact@v4
        with:
          name: trivy-results
          path: trivy-results.sarif
      - name: 🔐 Advanced Secret Detection
        run: |
          echo "🔍 Running security validation..."

          # Check for potential secrets (excluding false positives)
          echo "Checking for potential hardcoded secrets..."
          if grep -rE "(password|secret|api_key|auth_token|private_key):\s*['\"]?[A-Za-z0-9+/=]{10,}" . \
             --include="*.yml" --include="*.yaml" --include="*.py" --include="*.sh" \
             --exclude-dir=.git --exclude-dir=.github \
             --exclude="*example*" --exclude="*template*" \
             | grep -v "YOUR_.*_HERE\|test:test\|example\|template\|#.*token\|#.*secret\|README"; then
            echo "⚠️ Potential secrets found - please review"
            exit 1
          else
            echo "✅ No obvious secrets detected"
          fi

      - name: 🔒 File Permissions Check
        run: |
          echo "🔒 Checking file permissions..."

          # Check for world-writable files
          if find . -name "*.yml" -o -name "*.yaml" -o -name "*.py" -o -name "*.sh" | xargs ls -la | grep "^-.......rw"; then
            echo "❌ World-writable files found"
            find . -name "*.yml" -o -name "*.yaml" -o -name "*.py" -o -name "*.sh" | xargs ls -la | grep "^-.......rw"
            exit 1
          else
            echo "✅ File permissions look secure"
          fi

      - name: 🛡️ Security Summary
        if: always()
        run: |
          echo "## 🛡️ Security Validation Summary" >> $GITHUB_STEP_SUMMARY
          echo "✅ **DevSkim scan completed**" >> $GITHUB_STEP_SUMMARY
          echo "✅ **Secret detection completed**" >> $GITHUB_STEP_SUMMARY
          echo "✅ **File permissions checked**" >> $GITHUB_STEP_SUMMARY

  ansible-syntax-check:
    name:  Ansible Syntax Check
    runs-on: ubuntu-latest
    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4

      - name: 🔧 Set up Python & Install Dependencies
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      - run: |
          python -m pip install --upgrade pip
          pip install ansible-lint # We only need ansible-lint

      - name: 🎭 Run Ansible Lint
        id: lint # Give this step an ID to reference its outcome
        run: |
          # This single command lints all files, respects .ansible-lint config,
          # and creates the SARIF report.
          ansible-lint --sarif-file=ansible-results.sarif
        continue-on-error: true # Allow the workflow to continue to the upload step

      - name: 📤 Upload Ansible-Lint SARIF Report
        if: always() # Always run this step to upload the report
        uses: actions/upload-artifact@v4
        with:
          name: ansible-lint-results
          path: ansible-results.sarif

      - name: 📋 Check Linting Results
        if: steps.lint.outcome == 'failure'
        run: |
          echo "❌ Ansible-lint found issues."
          exit 1 # Explicitly fail the job if the linting step failed

  publish:
    name: 🚀 Publish to Confluence
    # Your conditions for running the job remain the same
    needs: [super-linter, security, ansible-syntax-check]
    if: >
      github.event_name == 'push' &&
      (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/heads/release/') || startsWith(github.ref, 'refs/heads/hotfix/')) &&
      needs.ansible-syntax-check.result == 'success'

    # 💡 1. The 'uses' key now calls your reusable workflow.
    # The runs-on and steps are removed.
    # Make sure to use the correct branch name or tag (e.g., @main).
    uses: KhalilGibrotha/bug-free-fiesta/.github/workflows/publish-docs.yml@main

    # 💡 2. Pass the required secrets to the reusable workflow.
    secrets:
      CONFLUENCE_URL: ${{ secrets.CONFLUENCE_URL }}
      CONFLUENCE_USER: ${{ secrets.CONFLUENCE_USER }}
      CONFLUENCE_API_TOKEN: ${{ secrets.CONFLUENCE_API_TOKEN }}

# In ci.yml, this replaces all other summary/report jobs

  comprehensive-report:
    name: 📊 Generate Comprehensive Report
    # This job runs after all checks are complete
    needs: [super-linter, security, ansible-syntax-check]
    if: always() # Always run to report on success or failure
    runs-on: ubuntu-latest
    steps:
      - name: 📥 Download all artifacts
        uses: actions/download-artifact@v4
        with:
          # Download all artifacts into a 'reports' directory
          path: ./reports
        continue-on-error: true

      - name: 🐍 Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: � Checkout Code (for scripts)
        uses: actions/checkout@v4

      - name: 📝 Generate Summary from All Reports
        run: python scripts/generate_sarif_summary.py